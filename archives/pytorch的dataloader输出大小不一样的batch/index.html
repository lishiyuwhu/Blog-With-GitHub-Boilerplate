<!DOCTYPE HTML>
<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Plams,blog" />
    <meta name="generator" content="Maverick 1.1" />
    <meta name="template" content="Galileo" />
    <link rel="alternate" type="application/rss+xml" title="Plams的个人博客 &raquo; RSS 2.0" href="/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="Plams的个人博客 &raquo; ATOM 1.0" href="/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/galileo-3f4dcc35c9.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/ExSearch/ExSearch-182e5a8868.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/katex.min.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700&display=swap">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/f425b02e0d5eda0c04240f1d3db2d2b9.json"
        }
    </script>
    
<title>pytorch的dataloader输出大小不一样的batch - Plams的个人博客</title>
<meta name="author" content="" />
<meta name="description" content="pytorch的dataloader输出大小不一样的batch" />
<meta property="og:title" content="pytorch的dataloader输出大小不一样的batch - Plams的个人博客" />
<meta property="og:description" content="pytorch的dataloader输出大小不一样的batch" />
<meta property="og:site_name" content="Plams的个人博客" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/archives/pytorch的dataloader输出大小不一样的batch/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2020-10-14T21:31:00-00.00" />
<meta name="twitter:title" content="pytorch的dataloader输出大小不一样的batch - Plams的个人博客" />
<meta name="twitter:description" content="pytorch的dataloader输出大小不一样的batch" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
<meta http-equiv="x-dns-prefetch-control" content="on">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net" />

    </head>
    
    <body>
        
        <div class="container">
            <header id="ga-header">
                <div first>
                    <aside id="ga-brand">
                        <h1 class="brand"><a class="no-style" href="/">Plams的个人博客</a></h1>
                        <p>Destination Determination Deliberation</p>
                    </aside>
                </div>
                <div second id="ga-nav">
                    <nav class="navs">
                        <ul><li><a class="ga-highlight" href="/" target="_self">首页</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/archives/" target="_self">归档</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/about/" target="_self">关于</a></li><span class="separator">·</span><li><a href="#" target="_self" class="search-form-input ga-highlight">搜索</a></li></ul>
                    </nav>
                </div>
            </header>
            <div class="wrapper">
                
<main>    
    <section class="ga-section ga-content">
        <article class="yue">
            <h1 class="ga-post_title">pytorch的dataloader输出大小不一样的batch</h1>
            <span class="ga-post_meta ga-mono">
                <span></span>
                <time>
                    2020-10-14
                </time>
                
                in <a no-style class="category" href="/category/Default/">
                    Default
                </a>
                
                
            </span>
            <div class="ga-content_body">
                <h1>pytorch的dataloader输出大小不一样的batch</h1>
<h2>问题出现</h2>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MYDATASET</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">soft_data_dir</span><span class="p">,</span> <span class="n">transforms_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
                <span class="o">***************************</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
                <span class="o">**********************</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;A_256&#39;</span><span class="p">:</span> <span class="n">item_A</span><span class="p">,</span> <span class="s1">&#39;B_256&#39;</span><span class="p">:</span> <span class="n">item_B</span><span class="p">,</span> <span class="s1">&#39;A_512&#39;</span><span class="p">:</span> <span class="n">item_A_512</span><span class="p">,</span> <span class="s1">&#39;B_512&#39;</span><span class="p">:</span> <span class="n">item_B_512</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">files_A</span><span class="p">)</span>
</pre></div>
<p>期望返回的dict中, 256代表256*256大小的图片, dict中含有两种大小的输出, 在使用时</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
  <span class="c1"># Set model input</span>
  <span class="n">real_A_256</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">input_source_256</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;A_256&#39;</span><span class="p">]))</span>
  <span class="n">real_B_512</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">input_target_512</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;B_512&#39;</span><span class="p">]))</span>
</pre></div>
<p>若batchsize=1或者num_workers&gt;1的情况下会报错<code>RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0.</code></p>
<p>这是因为dataloader在把dataset的<code>__getitem__</code>输出拼合成batch的时候无法处理dict这种数据</p>
<h2>解决方法 -&gt;  collate_fn</h2>
<p>DataLoader可以配置collate_fn参数, 用于拼合各个样本. 报错也正是默认的<code>default_collate</code>函数中<code>torch.stack(batch, 0, out=out)</code>部分出错</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">transforms_</span> <span class="o">=</span> <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
               <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))]</span>  <span class="c1"># (0,1) -&gt; (-1,1)</span>

<span class="k">class</span> <span class="nc">TmpSET</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transforms_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;./dlrb.jpeg&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transforms_</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
      <span class="n">img_A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">Image</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">)</span>
      <span class="n">img_B</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">Image</span><span class="o">.</span><span class="n">BILINEAR</span><span class="p">)</span>
      <span class="n">item_A</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img_A</span><span class="p">)</span>
      <span class="n">item_B</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img_B</span><span class="p">)</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">item_A</span><span class="p">,</span> <span class="n">item_A</span><span class="p">,</span> <span class="n">item_B</span><span class="p">,</span> <span class="n">item_B</span><span class="p">]</span>
    <span class="c1"># return {&#39;A_256&#39;: item_A, &#39;B_256&#39;: item_B, &#39;A_512&#39;: item_A, &#39;B_512&#39;: item_B}</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
      <span class="k">return</span> <span class="mi">100</span>

    <span class="k">def</span> <span class="nf">my_collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
      <span class="n">A_256</span><span class="p">,</span> <span class="n">B_256</span><span class="p">,</span> <span class="n">A_512</span><span class="p">,</span> <span class="n">B_512</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">batch</span><span class="p">)</span>
      <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">A_256</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">B_256</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">A_512</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">B_512</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>


    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">TmpSET</span><span class="p">(</span><span class="n">transforms_</span><span class="o">=</span><span class="n">transforms_</span><span class="p">),</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">my_collate_fn</span><span class="p">)</span>


    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
      <span class="c1"># print(batch[1].shape)</span>
      <span class="c1"># print(batch[2].shape)</span>
      <span class="c1"># print(batch[3].shape)</span>
      <span class="k">break</span>

<span class="c1">########################################################################</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">])</span>
<span class="c1">########################################################################</span>
</pre></div>
<p>这样, 简单的在my_collate_fn中把list拆开手动使用torch.stack合并各项, 就可以正确得到各个nchw的batch数据了</p>

            </div>
        </article>
        <div id="ga-tags">
    
</div>
    </section>

    
<section id="ga-content_pager">

    <div class="next">
        <a class="ga-highlight" href="/archives/torch.upsample转ONNX的问题/">torch.upsample转ONNX的问题</a>
        <p class="yue">问题</p>
    </div>


    <div class="prev">
        <a class="ga-highlight" href="/archives/解决_csv.Error line contains NULL byte/">解决_csv.Error line contains NULL byte</a>
        <p class="yue">fi = open(&#39;dev.tsv&#39;, &#39;rb&#39;)</p>
    </div>

</section>


    

</main>

                <footer class="ga-mono" id="ga-footer">
                    <section>
                        <span id="ga-uptime"></span>
                        <span class="brand">Plams的个人博客</span>
                    </section>
                    <section>
                        <p class="copyright">
                            <span>Copyright © 2021 Plams</span>
                            <span>Powered by <a no-style href="https://github.com/AlanDecode/Maverick" target="_blank">Maverick & Galileo</a></span>
                        </p>
                        <div class="copyright">
                            <span class="footer-addon">
                                
                            </span>
                            <nav class="social-links">
                                <ul><li><a class="no-style" title="GitHub" href="https://github.com/lishiyuwhu" target="_blank"><i class="gi gi-github"></i>GitHub</a></li></ul>
                            </nav>
                        </div>
                    </section>
                    <script>
                        var site_build_date = "2018-3-28T16:16+08:00"
                    </script>
                    <script src="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/galileo-dc4baa7cf4.js"></script>
                </footer>
            </div>
        </div>
    </div>

    <!--katex-->
    <script defer src="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/katex.min.js"></script>
    <script>
    mathOpts = {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false}
        ]
    };
    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    <script src="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/lishiyuwhu/Blog-With-GitHub-Boilerplate@gh-pages/assets/ExSearch/ExSearch-493cb9cd89.js"></script>

    
    </body>
</html>